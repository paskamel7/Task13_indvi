{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFyt6ql7kBgX",
        "outputId": "f91109e1-4375-4de1-ee8b-43fec149a923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from re import X\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root= 'data',\n",
        "    train= True,\n",
        "    transform= ToTensor(),\n",
        "    download= True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root= 'data',\n",
        "    train= False,\n",
        "    transform= ToTensor(),\n",
        "    download= True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1nArFnALk0sS",
        "outputId": "6012920a-8391-41a3-f87a-c74af714200b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 5.267636\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.410453\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.146905\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.877725\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.768968\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.635097\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.580552\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.151091\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.098768\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.912780\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.866934\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.922944\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.812461\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.958470\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.795921\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.655109\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.740463\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.587491\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.517166\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.622833\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.563900\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.566702\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.496951\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.543951\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.624379\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.621456\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.509313\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.576153\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.426819\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.437867\n",
            "\n",
            "Test set: Average loss: 0.1732, Accuracy: 9511/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.365612\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.279397\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.449574\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.399871\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.437034\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.474483\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.562276\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9381e0454c2d>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m      \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m      \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9381e0454c2d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mper_device_and_dtype_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         self.record = torch.ops.profiler._record_function_enter_new(\n\u001b[0m\u001b[1;32m    689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loaders = {\n",
        "    'train' : DataLoader(train_data,batch_size=100,shuffle=True,num_workers=1)\n",
        "   ,'test' : DataLoader(test_data,batch_size=100,shuffle=True,num_workers=1)\n",
        "}\n",
        "loaders\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.bn1 = nn.BatchNorm2d(10)\n",
        "        self.bn2 = nn.BatchNorm2d(20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.bn1(self.conv1(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.bn2(self.conv2(x))), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        return F.log_softmax(self.fc2(x), dim=1)\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'])\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
        "          f'({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "     train(epoch)\n",
        "     test()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "QK2U5TAolXGd",
        "outputId": "b049ccc1-84d3-47fe-adac-73585bc2daa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.eval()\n",
        "data, target = test_data[3000]\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "print(f'Prediction: {prediction}')\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
